{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "560709f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/az/Learn/.venv/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# @title Imports\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import os\n",
    "import requests\n",
    "from matplotlib import colors\n",
    "from matplotlib import rcParams\n",
    "from matplotlib.colors import ListedColormap\n",
    "from numpy import pi\n",
    "from copy import copy\n",
    "import ipywidgets as widgets  # interactive display\n",
    "\n",
    "# @title Figure settings\n",
    "rcParams['figure.figsize'] = [20, 4]\n",
    "rcParams['font.size'] = 11\n",
    "rcParams['axes.spines.top'] = False\n",
    "rcParams['axes.spines.right'] = False\n",
    "rcParams['figure.autolayout'] = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7c136384",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>trial_index</th>\n",
       "      <th>trial_time</th>\n",
       "      <th>response_arrow_start_angle</th>\n",
       "      <th>motion_direction</th>\n",
       "      <th>motion_coherence</th>\n",
       "      <th>estimate_x</th>\n",
       "      <th>estimate_y</th>\n",
       "      <th>reaction_time</th>\n",
       "      <th>raw_response_time</th>\n",
       "      <th>prior_std</th>\n",
       "      <th>prior_mean</th>\n",
       "      <th>subject_id</th>\n",
       "      <th>experiment_name</th>\n",
       "      <th>experiment_id</th>\n",
       "      <th>session_id</th>\n",
       "      <th>run_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>225</td>\n",
       "      <td>0.12</td>\n",
       "      <td>-1.749685</td>\n",
       "      <td>-1.785666</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10</td>\n",
       "      <td>225</td>\n",
       "      <td>1</td>\n",
       "      <td>data01_direction4priors</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2.730730</td>\n",
       "      <td>NaN</td>\n",
       "      <td>225</td>\n",
       "      <td>0.12</td>\n",
       "      <td>-1.819693</td>\n",
       "      <td>-1.714269</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10</td>\n",
       "      <td>225</td>\n",
       "      <td>1</td>\n",
       "      <td>data01_direction4priors</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>4.913950</td>\n",
       "      <td>NaN</td>\n",
       "      <td>235</td>\n",
       "      <td>0.06</td>\n",
       "      <td>-1.562674</td>\n",
       "      <td>-1.951422</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10</td>\n",
       "      <td>225</td>\n",
       "      <td>1</td>\n",
       "      <td>data01_direction4priors</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>6.997296</td>\n",
       "      <td>NaN</td>\n",
       "      <td>225</td>\n",
       "      <td>0.06</td>\n",
       "      <td>-1.601388</td>\n",
       "      <td>-1.919781</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10</td>\n",
       "      <td>225</td>\n",
       "      <td>1</td>\n",
       "      <td>data01_direction4priors</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>9.097130</td>\n",
       "      <td>NaN</td>\n",
       "      <td>215</td>\n",
       "      <td>0.24</td>\n",
       "      <td>-1.639461</td>\n",
       "      <td>-1.887371</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10</td>\n",
       "      <td>225</td>\n",
       "      <td>1</td>\n",
       "      <td>data01_direction4priors</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   trial_index  trial_time  response_arrow_start_angle  motion_direction  \\\n",
       "0            1    0.000000                         NaN               225   \n",
       "1            2    2.730730                         NaN               225   \n",
       "2            3    4.913950                         NaN               235   \n",
       "3            4    6.997296                         NaN               225   \n",
       "4            5    9.097130                         NaN               215   \n",
       "\n",
       "   motion_coherence  estimate_x  estimate_y  reaction_time  raw_response_time  \\\n",
       "0              0.12   -1.749685   -1.785666            NaN                NaN   \n",
       "1              0.12   -1.819693   -1.714269            NaN                NaN   \n",
       "2              0.06   -1.562674   -1.951422            NaN                NaN   \n",
       "3              0.06   -1.601388   -1.919781            NaN                NaN   \n",
       "4              0.24   -1.639461   -1.887371            NaN                NaN   \n",
       "\n",
       "   prior_std  prior_mean  subject_id          experiment_name  experiment_id  \\\n",
       "0         10         225           1  data01_direction4priors             11   \n",
       "1         10         225           1  data01_direction4priors             11   \n",
       "2         10         225           1  data01_direction4priors             11   \n",
       "3         10         225           1  data01_direction4priors             11   \n",
       "4         10         225           1  data01_direction4priors             11   \n",
       "\n",
       "   session_id  run_id  \n",
       "0           1       1  \n",
       "1           1       1  \n",
       "2           1       1  \n",
       "3           1       1  \n",
       "4           1       1  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"data01_direction4priors.csv\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f17dd743",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    224.416887\n",
      "1    226.708718\n",
      "2    218.687309\n",
      "3    219.833224\n",
      "4    220.979140\n",
      "Name: estimated_degree, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Calculate estimated degree in a new field with this name\n",
    "# estimated_degree = np.degrees(np.arctan2(data['estimate_x'], data['estimate']))\n",
    "data['estimated_degree'] = (np.degrees(np.arctan2(data['estimate_x'], data['estimate_y'])) + 360) % 360\n",
    "print(data['estimated_degree'].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1de61998",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "99efc0122ea94e428d690657ea0a1189",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='Subject:', options=(np.int64(1), np.int64(2), np.int64(3), np.int6â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import ipywidgets as widgets\n",
    "import numpy as np\n",
    "\n",
    "# Widget for choosing subject\n",
    "subject_options = sorted(data['subject_id'].unique())\n",
    "@widgets.interact(subject=widgets.Dropdown(options=subject_options, description='Subject:'))\n",
    "def plot_histograms(subject):\n",
    "    # Filter data for selected subject\n",
    "    subj_data = data[data['subject_id'] == subject]\n",
    "    # Get unique prior_std and motion_coherence values\n",
    "    prior_stds = sorted(subj_data['prior_std'].dropna().unique())\n",
    "    motion_coherences = sorted(subj_data['motion_coherence'].dropna().unique())\n",
    "    \n",
    "    n_rows = len(prior_stds)\n",
    "    n_cols = len(motion_coherences)\n",
    "    fig, axes = plt.subplots(n_rows, n_cols, figsize=(4*n_cols, 3*n_rows), sharex=True, sharey=True)\n",
    "    if n_rows == 1 and n_cols == 1:\n",
    "        axes = np.array([[axes]])\n",
    "    elif n_rows == 1:\n",
    "        axes = axes[np.newaxis, :]\n",
    "    elif n_cols == 1:\n",
    "        axes = axes[:, np.newaxis]\n",
    "    \n",
    "    for i, prior_std in enumerate(prior_stds):\n",
    "        for j, motion_coh in enumerate(motion_coherences):\n",
    "            ax = axes[i, j]\n",
    "            # Filter for this prior_std and motion_coherence\n",
    "            filt = (subj_data['prior_std'] == prior_std) & (subj_data['motion_coherence'] == motion_coh)\n",
    "            trials = subj_data[filt]\n",
    "            # Get true direction and estimated degree, drop NaN\n",
    "            true_dir = trials['motion_direction'].dropna()\n",
    "            est_deg = trials['estimated_degree'].dropna()\n",
    "            # Plot histograms\n",
    "            # print(trials.shape)\n",
    "            bins = np.linspace(0, 360, 37)  # 10 degree bins\n",
    "            ax.hist(true_dir % 360, bins=bins, alpha=0.6, label='True Direction', color='tab:blue')\n",
    "            ax.hist(est_deg % 360, bins=bins, alpha=0.6, label='Estimated Degree', color='tab:orange')\n",
    "            ax.set_title(f'Prior std: {prior_std}, Coh: {motion_coh}')\n",
    "            ax.set_xlim(0, 360)\n",
    "            ax.set_xticks([0, 90, 180, 270, 360])\n",
    "            if i == n_rows - 1:\n",
    "                ax.set_xlabel('Degrees')\n",
    "            if j == 0:\n",
    "                ax.set_ylabel('Count')\n",
    "            ax.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2857d7a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute log likelihood for fitting basic Bayesian model\n",
    "\n",
    "# Assume: \n",
    "# - data has columns: 'motion_direction' (true direction), 'estimated_degree' (subject's estimate), \n",
    "#   'prior_mean', 'prior_std', 'motion_coherence', 'subject_id'\n",
    "# - We fit a model where the subject's estimate is a noisy Bayesian posterior mean of the true direction,\n",
    "#   with noise (likelihood std) as a free parameter.\n",
    "\n",
    "from scipy.stats import norm\n",
    "\n",
    "def compute_log_likelihood(data, likelihood_std):\n",
    "    \"\"\"\n",
    "    Compute the log likelihood of the observed estimates under a basic Bayesian model.\n",
    "    Args:\n",
    "        data: DataFrame with columns 'motion_direction', 'estimated_degree', 'prior_mean', 'prior_std'\n",
    "        likelihood_std: assumed std of likelihood (sensory noise)\n",
    "    Returns:\n",
    "        log_likelihood: float\n",
    "    \"\"\"\n",
    "    # Drop rows with missing values\n",
    "    df = data.dropna(subset=['motion_direction', 'estimated_degree', 'prior_mean', 'prior_std'])\n",
    "    # Compute Bayesian posterior mean and std for each trial\n",
    "    prior_var = df['prior_std'] ** 2\n",
    "    likelihood_var = likelihood_std ** 2\n",
    "    # Posterior mean\n",
    "    post_mean = (df['motion_direction'] / likelihood_var + df['prior_mean'] / prior_var) / (1/likelihood_var + 1/prior_var)\n",
    "    # Posterior std\n",
    "    post_std = np.sqrt(1 / (1/likelihood_var + 1/prior_var))\n",
    "    # Compute log likelihood of observed estimate under posterior\n",
    "    log_likelihoods = norm.logpdf(df['estimated_degree'], loc=post_mean, scale=post_std)\n",
    "    total_log_likelihood = np.sum(log_likelihoods)\n",
    "    return total_log_likelihood\n",
    "\n",
    "# Example usage:\n",
    "# loglike = compute_log_likelihood(data, likelihood_std=20)\n",
    "# print(\"Log likelihood (likelihood_std=20):\", loglike)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fcca22bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reaction time statistics by subject:\n",
      "                mean    median       std\n",
      "subject_id                              \n",
      "1           1.491732  1.438569  0.457612\n",
      "5           1.123234  1.079921  0.303347\n",
      "6           1.329796  1.272664  0.354293\n",
      "10          1.186519  1.129499  0.339246\n",
      "\n",
      "Reaction time statistics by subject (subjects 2, 3, 4, 7, 8, 9, 11, 12):\n",
      "                mean    median       std\n",
      "subject_id                              \n",
      "3           1.451398  1.409753  0.392336\n",
      "7           1.579214  1.512977  0.547037\n",
      "8           1.308775  1.203492  0.478837\n",
      "9           1.322304  1.267986  0.395029\n",
      "11          1.236222  1.187572  0.407068\n",
      "12          1.463959  1.437616  0.452006\n"
     ]
    }
   ],
   "source": [
    "# Calculate mean, median, and std of reaction time for each subject, dropping NaN values\n",
    "data_coherence_012 = data[data[\"motion_coherence\"] == 0.12]\n",
    "\n",
    "reaction_time_stats = (\n",
    "    data_coherence_012[data_coherence_012['subject_id'].isin([1, 5, 6, 10])]\n",
    "        .dropna(subset=['reaction_time'])\n",
    "        .groupby('subject_id')['reaction_time']\n",
    "        .agg(['mean', 'median', 'std'])\n",
    ")\n",
    "print(\"Reaction time statistics by subject:\")\n",
    "print(reaction_time_stats)\n",
    "\n",
    "# Calculate mean, median, and std of reaction time for the other set of subjects, dropping NaN values\n",
    "reaction_time_stats_others = (\n",
    "    data_coherence_012[data_coherence_012['subject_id'].isin([2, 3, 4, 7, 8, 9, 11, 12])]\n",
    "        .dropna(subset=['reaction_time'])\n",
    "        .groupby('subject_id')['reaction_time']\n",
    "        .agg(['mean', 'median', 'std'])\n",
    ")\n",
    "print(\"\\nReaction time statistics by subject (subjects 2, 3, 4, 7, 8, 9, 11, 12):\")\n",
    "print(reaction_time_stats_others)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "118db15f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log likelihood (simple model): 1.844184255993981\n",
      "Log likelihood (quadratic model): 3.4672541225567635\n",
      "Quadratic model parameters: a=1.064, b=-0.396, c=0.520\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "\n",
    "x = np.array([1, 2, 3, 4, 5])\n",
    "y = np.array([1.2, 3.9, 9.1, 15.8, 25.2])  # roughly y = x^2 + noise\n",
    "\n",
    "# Model 1: y_hat = x^2 (no parameters)\n",
    "y_hat = x ** 2\n",
    "residuals = y - y_hat\n",
    "\n",
    "\n",
    "y_hat_simple = x ** 2\n",
    "residuals_simple = y - y_hat_simple\n",
    "n = len(y)\n",
    "sigma2 = np.sum(residuals**2) / n\n",
    "sigma2_simple = np.sum(residuals_simple**2) / n\n",
    "\n",
    "log_likelihood_simple = -0.5 * n * np.log(2 * math.pi * sigma2_simple) - (np.sum(residuals_simple**2) / (2 * sigma2_simple))\n",
    "print(\"Log likelihood (simple model):\", log_likelihood_simple)\n",
    "\n",
    "# Model 2: y_hat = a * x^2 + b * x + c (quadratic with parameters)\n",
    "# Fit quadratic model using numpy polyfit\n",
    "params = np.polyfit(x, y, 2)  # returns [a, b, c]\n",
    "a, b, c = params\n",
    "y_hat_quad = a * x**2 + b * x + c\n",
    "residuals_quad = y - y_hat_quad\n",
    "sigma2_quad = np.sum(residuals_quad**2) / n\n",
    "\n",
    "log_likelihood_quad = -0.5 * n * np.log(2 * math.pi * sigma2_quad) - (np.sum(residuals_quad**2) / (2 * sigma2_quad))\n",
    "print(\"Log likelihood (quadratic model):\", log_likelihood_quad)\n",
    "print(\"Quadratic model parameters: a=%.3f, b=%.3f, c=%.3f\" % (a, b, c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c34115fd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "832e319a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.844184255993981\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64ada97f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
